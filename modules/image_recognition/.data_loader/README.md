data_loader는 Path, Image, Label 전부를 메모리에 동적으로 업로드 하여 메모리를 최대한 아끼면서 지연없이 AI 모델을 학습시키는 것을 목표로 개발되었다.
그러나, 개발 중 이 과정이 필요 없는 것을 느꼈다.
아무리 많은 데이터라도, 현재 내가 쓰는 데이터는 고작 250GB이고, 이것의 경로를 메모리에 올리면 1GB도 되지 않는다.
AI 테스트가 더 급한 상황에서 이 것을 코딩하는 것은 너무 무모하다.

기존의 있는 라이브러리, 기술을 잘 활용해야 한다.

그래도, 미래의 내가 이 프로그램을 한번 더 볼 수 있으니 기록한다.

목표: Path, Image, Label 전부를 메모리에 동적으로 업로드하여 메모리를 최대한 아끼면서 지연없이 AI 모델을 학습시키는 것
현재 문제점
  1. Python 언어의 한계. 메모리 접근 시간이 너무 느리다. 마지막으로 코딩할 때, C++로 랭기지를 바꿀까 생각했다.
  2. ILSVRC Test.py의 테스트 코드를 디버깅하는 과정이었다. 메모리 초기화가 느려서 중단되는 문제인지, 다른 문제 인지 모르겠지만 알 수 없는 오류로 중단된다. 원인은 1GB 이상의 메모리를 0 바이트로 초기화하는 명령을 실행하는 것이다.
  3. 전체적인 코드는 완성되었다. 디버깅만 하면 된다.
