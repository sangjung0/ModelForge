{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "os.chdir(\"/workspaces/dev/modules\")\n",
    "sys.path.append(\"/workspaces/dev/models/R-CNN\")\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit=false\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1 inter_op_parallelism_threads=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 13:09:43.980163: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-12 13:09:43.990352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741784984.003333    9650 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741784984.006642    9650 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 13:09:44.017648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pills.GenerativeSequence import GenerativeSequence\n",
    "from PillNet import PillNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH = '/workspaces/dev/datasets/pills/data'\n",
    "LABEL_PATH = '/workspaces/dev/datasets/pills/class_label.csv'\n",
    "BACKGROUND_IMAGEES_PATH = '/workspaces/dev/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_SIZE = 800000\n",
    "VALIDATION_DATA_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "INPUT_SIZE = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741784986.330997    9650 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9502 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PillNet.__crop_regions of <tensorflow.python.eager.polymorphic_function.tf_method_target.TfMethodTarget object at 0x7f48947f4340>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PillNet.__crop_regions of <tensorflow.python.eager.polymorphic_function.tf_method_target.TfMethodTarget object at 0x7f48947f4340>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pill_net\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"pill_net\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ROI (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">138,337</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DetectionHead (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">675,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FeatureExtractor (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ CentroidHead (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,422</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ SegmentationHead (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,385</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ClassificationHead (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">210,728</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ROI (\u001b[38;5;33mSequential\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │       \u001b[38;5;34m138,337\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ DetectionHead (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │       \u001b[38;5;34m675,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FeatureExtractor (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m32,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ CentroidHead (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m5,422\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ SegmentationHead (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m34,385\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ClassificationHead (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │       \u001b[38;5;34m210,728\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,096,396</span> (4.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,096,396\u001b[0m (4.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,096,396</span> (4.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,096,396\u001b[0m (4.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PillNet(BATCH_SIZE, 50, INPUT_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = GenerativeSequence(\n",
    "  TRAIN_DATA_SIZE, BATCH_SIZE, input_size = INPUT_SIZE[:2],material_path=SOURCE_PATH,\n",
    "  label_path=LABEL_PATH, background_images_path=BACKGROUND_IMAGEES_PATH,\n",
    "  use_multiprocessing=True, workers = 12\n",
    ")\n",
    "validation_sequence = GenerativeSequence(\n",
    "  VALIDATION_DATA_SIZE, BATCH_SIZE, input_size = INPUT_SIZE[:2],material_path=SOURCE_PATH,\n",
    "  label_path=LABEL_PATH, background_images_path=BACKGROUND_IMAGEES_PATH,\n",
    "  use_multiprocessing=True, workers = 8\n",
    ")\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "  lambda: train_sequence, \n",
    "  output_signature=(\n",
    "    tf.TensorSpec(shape=(BATCH_SIZE, INPUT_SIZE[0], INPUT_SIZE[1], INPUT_SIZE[2]), dtype=tf.float32),\n",
    "    {\n",
    "      \"roi\": tf.TensorSpec(shape=(BATCH_SIZE, INPUT_SIZE[0], INPUT_SIZE[1]), dtype=tf.bool),\n",
    "      \"centroid\": tf.TensorSpec(shape=(BATCH_SIZE * 16, 2), dtype=tf.float32),\n",
    "      \"detection\": tf.TensorSpec(shape=(BATCH_SIZE * 16, 4), dtype=tf.float32),\n",
    "      \"segmentation\": tf.TensorSpec(shape=(BATCH_SIZE * 16, INPUT_SIZE[0]//4, INPUT_SIZE[1]//4), dtype=tf.bool),\n",
    "      \"classification\": tf.TensorSpec(shape=(BATCH_SIZE * 16), dtype=tf.uint32)\n",
    "    }\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(jit_compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "  filepath=\"/workspaces/dev/models/R-CNN/checkpoints/pill_net.keras\",\n",
    "  monitor=\"val_loss\",\n",
    "  save_best_only=True,\n",
    "  save_weights_only=False,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "  monitor=\"val_loss\",\n",
    "  patience=10,\n",
    "  restore_best_weights=True,\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['pill_net/SegmentationHead/conv2d_16/kernel', 'pill_net/SegmentationHead/conv2d_16/bias', 'pill_net/SegmentationHead/conv2d_17/kernel', 'pill_net/SegmentationHead/conv2d_17/bias', 'pill_net/SegmentationHead/conv2d_18/kernel', 'pill_net/SegmentationHead/conv2d_18/bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741785040.422904    9780 service.cc:148] XLA service 0x7f475000d320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741785040.422951    9780 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "I0000 00:00:1741785040.431351    9780 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1741785040.493297    9780 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-03-12 13:10:46.085705: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-12 13:10:50.073030: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1834', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:50.334948: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1834', 436 bytes spill stores, 436 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:50.423976: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2656', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:50.525777: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2013', 424 bytes spill stores, 424 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:50.716367: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1834', 2140 bytes spill stores, 2036 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:50.739184: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2161', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-03-12 13:10:52.441056: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng3{k11=0} for conv (f32[512,12,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,3,64,64]{3,2,1,0}, f32[12,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=3, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-12 13:10:53.183560: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.742616562s\n",
      "Trying algorithm eng3{k11=0} for conv (f32[512,12,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,3,64,64]{3,2,1,0}, f32[12,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=3, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-12 13:10:54.183829: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{} for conv (f32[512,12,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,3,64,64]{3,2,1,0}, f32[12,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=3, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-12 13:10:55.250283: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.066603964s\n",
      "Trying algorithm eng4{} for conv (f32[512,12,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,3,64,64]{3,2,1,0}, f32[12,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=3, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-12 13:11:07.443564: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[512,64,65,65]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,64,32,32]{3,2,1,0}, f32[64,64,5,5]{3,2,1,0}), window={size=5x5 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-03-12 13:11:08.060176: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.616786442s\n",
      "Trying algorithm eng0{} for conv (f32[512,64,65,65]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,64,32,32]{3,2,1,0}, f32[64,64,5,5]{3,2,1,0}), window={size=5x5 stride=2x2 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_sequence,\n",
    "  validation_data=validation_sequence,\n",
    "  epochs=100,\n",
    "  callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/workspaces/dev/models/R-CNN/checkpoints/pill_net_3.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
